{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "UwaeWjf3AMyh",
        "outputId": "71204c1e-7ad7-4cd8-e9e8-15db33107758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from pydrive) (1.12.11)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive) (1.35.0)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive) (1.31.6)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive) (0.17.4)\n",
            "Requirement already satisfied: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive) (1.15.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive) (0.0.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (2022.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (57.4.0)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (3.17.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (1.56.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (2.23.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (21.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.2->pydrive) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.2->pydrive) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.2->pydrive) (4.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->pydrive) (2.10)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     bull  D_MVA200  length    heigth  gain  MVA200_interact  \\\n",
              "date                                                                           \n",
              "2001-12-05 18:00:00     0 -1.004932      24  1.380822     1                0   \n",
              "2001-12-10 14:00:00     0 -0.780469      15  1.724340     1                0   \n",
              "2001-12-11 02:00:00     0  0.231401       6  0.356688     0                0   \n",
              "2001-12-18 22:00:00     0  3.738432       6  0.931116     1                0   \n",
              "2001-12-19 02:00:00     0  4.092700       4  1.183099     0                0   \n",
              "\n",
              "                     D_target  D_stop_trade  type_Double Bottom  \\\n",
              "date                                                              \n",
              "2001-12-05 18:00:00  3.761644      2.380822                   1   \n",
              "2001-12-10 14:00:00  4.448680      2.724340                   1   \n",
              "2001-12-11 02:00:00  1.713376      1.356688                   0   \n",
              "2001-12-18 22:00:00  2.862233      1.931116                   0   \n",
              "2001-12-19 02:00:00  3.366197      2.183099                   1   \n",
              "\n",
              "                     type_Double Top  resistance_support_none  \\\n",
              "date                                                            \n",
              "2001-12-05 18:00:00                0                        1   \n",
              "2001-12-10 14:00:00                0                        1   \n",
              "2001-12-11 02:00:00                1                        1   \n",
              "2001-12-18 22:00:00                1                        0   \n",
              "2001-12-19 02:00:00                0                        1   \n",
              "\n",
              "                     resistance_support_below  resistance_support_over  \\\n",
              "date                                                                     \n",
              "2001-12-05 18:00:00                         0                        0   \n",
              "2001-12-10 14:00:00                         0                        0   \n",
              "2001-12-11 02:00:00                         0                        0   \n",
              "2001-12-18 22:00:00                         1                        0   \n",
              "2001-12-19 02:00:00                         0                        0   \n",
              "\n",
              "                     resistance_support_inside  \n",
              "date                                            \n",
              "2001-12-05 18:00:00                          0  \n",
              "2001-12-10 14:00:00                          0  \n",
              "2001-12-11 02:00:00                          0  \n",
              "2001-12-18 22:00:00                          0  \n",
              "2001-12-19 02:00:00                          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-546e1794-94e6-41a7-9056-6416e7bedf06\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bull</th>\n",
              "      <th>D_MVA200</th>\n",
              "      <th>length</th>\n",
              "      <th>heigth</th>\n",
              "      <th>gain</th>\n",
              "      <th>MVA200_interact</th>\n",
              "      <th>D_target</th>\n",
              "      <th>D_stop_trade</th>\n",
              "      <th>type_Double Bottom</th>\n",
              "      <th>type_Double Top</th>\n",
              "      <th>resistance_support_none</th>\n",
              "      <th>resistance_support_below</th>\n",
              "      <th>resistance_support_over</th>\n",
              "      <th>resistance_support_inside</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2001-12-05 18:00:00</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.004932</td>\n",
              "      <td>24</td>\n",
              "      <td>1.380822</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3.761644</td>\n",
              "      <td>2.380822</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-12-10 14:00:00</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.780469</td>\n",
              "      <td>15</td>\n",
              "      <td>1.724340</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.448680</td>\n",
              "      <td>2.724340</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-12-11 02:00:00</th>\n",
              "      <td>0</td>\n",
              "      <td>0.231401</td>\n",
              "      <td>6</td>\n",
              "      <td>0.356688</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.713376</td>\n",
              "      <td>1.356688</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-12-18 22:00:00</th>\n",
              "      <td>0</td>\n",
              "      <td>3.738432</td>\n",
              "      <td>6</td>\n",
              "      <td>0.931116</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.862233</td>\n",
              "      <td>1.931116</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-12-19 02:00:00</th>\n",
              "      <td>0</td>\n",
              "      <td>4.092700</td>\n",
              "      <td>4</td>\n",
              "      <td>1.183099</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.366197</td>\n",
              "      <td>2.183099</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-546e1794-94e6-41a7-9056-6416e7bedf06')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-546e1794-94e6-41a7-9056-6416e7bedf06 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-546e1794-94e6-41a7-9056-6416e7bedf06');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Documentation gspread\n",
        "# https://docs.gspread.org/en/latest/user-guide.html\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "\n",
        "\n",
        "!pip install --upgrade -q gspread\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "\n",
        "# Insert custom functions\n",
        "!pip install pydrive                             # Package to use Google Drive API - not installed in Colab VM by default\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# Load historical Data\n",
        "# if you like using Google sheets.\n",
        "t_sheet_url = \"https://docs.google.com/spreadsheets/d/xxxx" #Replace with your own file URL\n",
        "tab_name = \"Train\"\n",
        "\n",
        "worksheet = gc.open_by_url(t_sheet_url)\n",
        "\n",
        "df = pd.DataFrame.from_records( \n",
        "    worksheet.worksheet(tab_name).get_all_values(),\n",
        "    )\n",
        "\n",
        "df.columns = df.loc[0].values\n",
        "df = df.iloc[ 1: ]\n",
        "\n",
        "type_dic = {\n",
        "    'bull' : int ,\n",
        "    'D_MVA200': float , \n",
        "    'length': int , \n",
        "    'heigth': float , \n",
        "    'type': str , \n",
        "    'entry': float , \n",
        "    'stop': float , \n",
        "    'gain': int ,\n",
        "    'target': float , \n",
        "    'stop_trade': float , \n",
        "    'resistance_support': str , \n",
        "    'MVA200_interact': int,\n",
        "    'D_target': float,\n",
        "    'D_stop_trade': float,\n",
        "    'pair': str\n",
        "}\n",
        "\n",
        "df = df.astype( type_dic )\n",
        "\n",
        "df = df.set_index(\"date\")\n",
        "\n",
        "df = df.drop(\n",
        "    columns = [\t \n",
        "                'entry', \n",
        "                'stop', \n",
        "                'target', \n",
        "                'stop_trade',\n",
        "               'pair'\n",
        "                ]\n",
        ")\n",
        "\n",
        "# Organice columns for model execution\n",
        "for col in df.select_dtypes(include=[\"object\"]).columns: # Recorre las columnas que son timpo object\n",
        "\n",
        "  for i in df[col].unique(): # Recorrer los posibles valores que estan en la columna\n",
        "\n",
        "    df[col+\"_\"+i] = np.where(df[col] == i, 1, 0) #Crear nueva columna agretando 1 o 0 dependiendo si tiene o no tiene el valor unico.\n",
        "\n",
        "  df = df.drop(columns=[col]) # Borrar la columna inicial.\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGeVI8-nBBoa"
      },
      "outputs": [],
      "source": [
        "#Load ML modules\n",
        "from sklearn.metrics import confusion_matrix # Para poder crear la matriz de confución\n",
        "from sklearn.metrics import (accuracy_score, precision_score,recall_score, roc_auc_score, f1_score) # Para calcular la presición de cada parte de la matriz de confusión\n",
        "from sklearn.model_selection import train_test_split #Importamos la libreria para definir los datasets de train y test\n",
        "\n",
        "# Over and undersampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "\n",
        "# Cargar modelos\n",
        "from sklearn.tree import DecisionTreeClassifier #Importamos el modelo de Arbol\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression # Libreria para regresión Logistica\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import lightgbm as lgb #pip install lightgbm\n",
        "import xgboost as xgb #pip install xgboost\n",
        "\n",
        "# Libreria para realizar el PCA\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPgmoGqTxQx6"
      },
      "outputs": [],
      "source": [
        "test_array = [\n",
        "  \"Baja///\",\n",
        "  \"Alta///\",\n",
        "  \"Baja/Oversample//\",\n",
        "  \"Alta/Oversample//\",\n",
        "  \"Baja/Undersample//\",\n",
        "  \"Alta/Undersample//\",\n",
        "  \"Baja//Normal/\",\n",
        "  \"Alta//Normal/\",\n",
        "  \"Baja/Oversample/Normal/\",\n",
        "  \"Alta/Oversample/Normal/\",\n",
        "  \"Baja/Undersample/Normal/\",\n",
        "  \"Alta/Undersample/Normal/\",\n",
        "  \"Baja///PCA\",\n",
        "  \"Alta///PCA\",\n",
        "  \"Baja/Oversample//PCA\",\n",
        "  \"Alta/Oversample//PCA\",\n",
        "  \"Baja/Undersample//PCA\",\n",
        "  \"Alta/Undersample//PCA\",\n",
        "  \"Baja//Normal/PCA\",\n",
        "  \"Alta//Normal/PCA\",\n",
        "  \"Baja/Oversample/Normal/PCA\",\n",
        "  \"Alta/Oversample/Normal/PCA\",\n",
        "  \"Baja/Undersample/Normal/PCA\",\n",
        "  \"Alta/Undersample/Normal/PCA\",\n",
        "  \"///\",\n",
        "  \"///\",\n",
        "  \"/Oversample//\",\n",
        "  \"/Oversample//\",\n",
        "  \"/Undersample//\",\n",
        "  \"/Undersample//\",\n",
        "  \"//Normal/\",\n",
        "  \"//Normal/\",\n",
        "  \"/Oversample/Normal/\",\n",
        "  \"/Oversample/Normal/\",\n",
        "  \"/Undersample/Normal/\",\n",
        "  \"/Undersample/Normal/\",\n",
        "  \"///PCA\",\n",
        "  \"///PCA\",\n",
        "  \"/Oversample//PCA\",\n",
        "  \"/Oversample//PCA\",\n",
        "  \"/Undersample//PCA\",\n",
        "  \"/Undersample//PCA\",\n",
        "  \"//Normal/PCA\",\n",
        "  \"//Normal/PCA\",\n",
        "  \"/Oversample/Normal/PCA\",\n",
        "  \"/Oversample/Normal/PCA\",\n",
        "  \"/Undersample/Normal/PCA\",\n",
        "  \"/Undersample/Normal/PCA\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0OiqLXFx8nd"
      },
      "outputs": [],
      "source": [
        "result = pd.DataFrame(columns=[\"Dataframe\",\"Modelo\",'accuracy','precision',\"precision_train\",'recall',\"f1score\",\"roc\",\"count\",\"matrix\"])\n",
        "c = 0 \n",
        "\n",
        "for list_test in test_array:\n",
        "\n",
        "  alza = False\n",
        "  baja = False\n",
        "  normalizar = False\n",
        "  undersample = False\n",
        "  oversample = False\n",
        "  double = False\n",
        "  pca = False\n",
        "\n",
        "  parameters = list_test.split(\"/\")\n",
        "  \n",
        "  if parameters[0] == \"Alza\":\n",
        "    alza = True\n",
        "\n",
        "  if parameters[0] == \"Baja\":\n",
        "    baja = True\n",
        "  \n",
        "  if parameters[1] == \"Oversample\":\n",
        "    undersample = True\n",
        "\n",
        "  if parameters[1] == \"Undersample\":\n",
        "    oversample = True\n",
        "\n",
        "  if parameters[2] == \"Normal\":\n",
        "    normalizar = True\n",
        "\n",
        "  if parameters[3] == \"PCA\":\n",
        "    pca = True  \n",
        "\n",
        "  # Normalizar columnas\n",
        "  if normalizar:\n",
        "\n",
        "    normal = pd.DataFrame()\n",
        "  \n",
        "    normal['D_MVA200'] = [np.linalg.norm(df.D_MVA200)]\n",
        "    df.D_MVA200 = df.D_MVA200/normal['D_MVA200'][0]\n",
        "\n",
        "    normal['length'] = [np.linalg.norm(df.length)]\n",
        "    df.length = df.length/normal['length'][0]\n",
        "\n",
        "    normal['heigth'] = [np.linalg.norm(df.heigth)]\n",
        "    df.heigth = df.heigth/normal['heigth'][0]\n",
        "\n",
        "    normal['heigth'] = [np.linalg.norm(df.heigth)]\n",
        "    df.heigth = df.heigth/normal['heigth'][0]\n",
        "\n",
        "  # Dejar solo baja\n",
        "  if baja:\n",
        "    df = df[ (df.bull == 0) & (df['type_Double Top'] == 1 ) & (df[\"resistance_support_none\"] == 0 ) ]\n",
        "\n",
        "  # Dejar solo Alta\n",
        "  if alza:\n",
        "    df = df[ (df.bull == 1) & (df['type_Double Bottom'] == 1 ) & (df[\"resistance_support_none\"] == 0 ) ]\n",
        "\n",
        "  # Creat data sets\n",
        "  x = df.drop(columns = 'gain') #Elimino de mi dataset la variable a predecir\n",
        "  y = df['gain'].astype(int) #Defino el Target\n",
        "\n",
        "\n",
        "  if pca:\n",
        "    pca = PCA()\n",
        "    components = pca.fit_transform( x )\n",
        "    \n",
        "    pca_array = []\n",
        "    a = 0\n",
        "    while a < len( x.columns ):\n",
        "      pca_array += [ \"PC\"+str(a + 1) ]\n",
        "      a += 1\n",
        "    \n",
        "    npc = np.array(components)\n",
        "    dfc = pd.DataFrame(npc, columns=pca_array)\n",
        "\n",
        "    x = dfc[[\"PC1\",\"PC2\"]]\n",
        "\n",
        "\n",
        "  #Generate 200 random numbers between 10 and 1000\n",
        "  import random\n",
        "  randomlist = random.sample(range(10, 100), 5)\n",
        "  for a in randomlist:\n",
        "\n",
        "    # Crear los dataset de entrenamiento y test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        x, \n",
        "        y,\n",
        "        stratify = y, # Matener una cantidad similar de observaciones positivas en cada data set\n",
        "        test_size = 0.20, \n",
        "        random_state = a\n",
        "        )\n",
        "    \n",
        "    if oversample:\n",
        "      # define oversampling strategy\n",
        "      oversample = RandomOverSampler(\n",
        "          sampling_strategy='minority',\n",
        "          random_state = a\n",
        "          )\n",
        "      # fit and apply the transform\n",
        "      X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
        "      X_train = X_over\n",
        "      y_train = y_over\n",
        "\n",
        "    if undersample:\n",
        "      # define undersample strategy\n",
        "      undersample = RandomUnderSampler(\n",
        "          sampling_strategy='majority',\n",
        "          random_state = a\n",
        "          )\n",
        "      # fit and apply the transform\n",
        "      X_over, y_over = undersample.fit_resample(X_train, y_train)\n",
        "      X_train = X_over\n",
        "      y_train = y_over\n",
        "\n",
        "      \n",
        "    ############ Tree\n",
        "\n",
        "    #Creamos la estructura del arbol\n",
        "    tree_fx = DecisionTreeClassifier(\n",
        "        max_depth=2,\n",
        "        min_samples_leaf = 100,\n",
        "        class_weight = \"balanced\",\n",
        "        random_state = 12,\n",
        "        criterion = \"entropy\",\n",
        "        splitter = \"random\",\n",
        "        max_features = None\n",
        "        ) \n",
        "\n",
        "    # Entrenamos el modelo utilizando tree_fx\n",
        "    tree_fx.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "    y_test_pred = tree_fx.predict(X_test) #Prediccion en Test\n",
        "    y_train_pred = tree_fx.predict(X_train) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"DecisionTreeClassifier\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ RandomForestClassifier\n",
        "\n",
        "    #Creamos un random forest!\n",
        "    RandomeForest_fx = RandomForestClassifier(\n",
        "        n_estimators = 50,\n",
        "        random_state = 12,\n",
        "        class_weight = \"balanced\",\n",
        "        criterion = \"entropy\",\n",
        "        max_depth = 30,\n",
        "        min_weight_fraction_leaf = 0.0,\n",
        "        max_features = \"log2\",\n",
        "        max_leaf_nodes = None,\n",
        "        min_impurity_decrease = 0.0,\n",
        "        ccp_alpha = 0.0005\n",
        "        )\n",
        "\n",
        "    RandomeForest_fx.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "    y_test_pred = RandomeForest_fx.predict(X_test) #Prediccion en Test\n",
        "    y_train_pred = RandomeForest_fx.predict(X_train) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"RandomForestClassifier\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ KNeighborsClassifier\n",
        "\n",
        "    knn = KNeighborsClassifier(\n",
        "        n_neighbors=10, # Cuantos puntos a tener en cuenta.\n",
        "        )\n",
        "\n",
        "\n",
        "    knn.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "\n",
        "    y_train_pred = knn.predict(X_train) #Prediccion en Train\n",
        "    y_test_pred = knn.predict(X_test) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"KNeighborsClassifier\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ LogisticRegression\n",
        "\n",
        "\n",
        "    # Paso 4: Creamos una instancia de la Regresión Logística\n",
        "    regresion = LogisticRegression(\n",
        "        random_state=12,\n",
        "        class_weight = \"balanced\",\n",
        "        solver = \"saga\",\n",
        "        max_iter = 100,\n",
        "        multi_class = \"auto\",\n",
        "        warm_start = False,\n",
        "        penalty='l2'\n",
        "    )\n",
        "\n",
        "    # Paso 5: Entrenamos la regresión logística con los datos de entrenamiento\n",
        "    regresion.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "    y_train_pred = regresion.predict(X_train) #Prediccion en Train\n",
        "    y_test_pred = regresion.predict(X_test) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"LogisticRegression\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ SVC\n",
        "    \n",
        "    SVC_model = SVC(\n",
        "        class_weight = \"balanced\",\n",
        "        random_state=12,\n",
        "        C = 150,\n",
        "        kernel = \"poly\", # Poly 27.94\n",
        "        degree = 2 # 1 25.11\n",
        "        )\n",
        "\n",
        "    # Entrenamos el modelo utilizando tree_fx\n",
        "    SVC_model.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "\n",
        "    y_train_pred = SVC_model.predict(X_train) #Prediccion en Train\n",
        "    y_test_pred = SVC_model.predict(X_test) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"SVC\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ GaussianNB\n",
        "\n",
        "    gnb = GaussianNB()\n",
        "\n",
        "    # Entrenamos el modelo utilizando tree_fx\n",
        "    gnb.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "\n",
        "    y_train_pred = gnb.predict(X_train) #Prediccion en Train\n",
        "    y_test_pred = gnb.predict(X_test) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"GaussianNB\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ BernoulliNB\n",
        "\n",
        "    bnb = BernoulliNB()\n",
        "\n",
        "    # Entrenamos el modelo utilizando tree_fx\n",
        "    bnb.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "\n",
        "    y_train_pred = bnb.predict(X_train) #Prediccion en Train\n",
        "    y_test_pred = bnb.predict(X_test) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"BernoulliNB\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ AdaBoostClassifier\n",
        "\n",
        "    adaboost = AdaBoostClassifier(\n",
        "        n_estimators=100, \n",
        "        random_state=0)\n",
        "\n",
        "    # Entrenamos el modelo utilizando tree_fx\n",
        "    adaboost.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "\n",
        "    y_train_pred = adaboost.predict(X_train) #Prediccion en Train\n",
        "    y_test_pred = adaboost.predict(X_test) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"AdaBoostClassifier\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ GradientBoostingClassifier\n",
        "\n",
        "    gbrt = GradientBoostingClassifier(random_state = 12)\n",
        "\n",
        "    # Entrenamos el modelo utilizando tree_fx\n",
        "    gbrt.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "\n",
        "    y_train_pred = gbrt.predict(X_train) #Prediccion en Train\n",
        "    y_test_pred = gbrt.predict(X_test) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"GradientBoostingClassifier\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ lightgbm\n",
        "\n",
        "    clf = lgb.LGBMClassifier(\n",
        "        random_state = 0\n",
        "    )\n",
        "\n",
        "    # Entrenamos el modelo\n",
        "    clf.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "\n",
        "    y_train_pred = clf.predict(X_train) #Prediccion en Train\n",
        "    y_test_pred = clf.predict(X_test) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"lightgbm\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ xgboost\n",
        "\n",
        "    clf_xgb = xgb.XGBClassifier()\n",
        "\n",
        "    # Entrenamos el modelo\n",
        "    clf_xgb.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "\n",
        "    y_train_pred = clf_xgb.predict(X_train) #Prediccion en Train\n",
        "    y_test_pred = clf_xgb.predict(X_test) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"xgboost\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    # Crear los dataset de entrenamiento y test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        x, \n",
        "        y,\n",
        "        stratify=y, # Matener una cantidad similar de observaciones positivas en cada data set\n",
        "        test_size=0.30, \n",
        "        random_state=214\n",
        "        )\n",
        "    \n",
        "    if oversample:\n",
        "      # define oversampling strategy\n",
        "      oversample = RandomOverSampler(\n",
        "          sampling_strategy='minority',\n",
        "          random_state = 456\n",
        "          )\n",
        "      # fit and apply the transform\n",
        "      X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
        "      X_train = X_over\n",
        "      y_train = y_over\n",
        "\n",
        "    if undersample:\n",
        "      # define undersample strategy\n",
        "      undersample = RandomUnderSampler(\n",
        "          sampling_strategy='majority',\n",
        "          random_state = 6921\n",
        "          )\n",
        "      # fit and apply the transform\n",
        "      X_over, y_over = undersample.fit_resample(X_train, y_train)\n",
        "      X_train = X_over\n",
        "      y_train = y_over\n",
        "    \n",
        "    ############ Tree\n",
        "\n",
        "    #Creamos la estructura del arbol\n",
        "    tree_fx = DecisionTreeClassifier(\n",
        "        max_depth=2,\n",
        "        min_samples_leaf = 100,\n",
        "        class_weight = \"balanced\",\n",
        "        random_state = 12,\n",
        "        criterion = \"entropy\",\n",
        "        splitter = \"random\",\n",
        "        max_features = None\n",
        "        ) \n",
        "\n",
        "    # Entrenamos el modelo utilizando tree_fx\n",
        "    tree_fx.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "    y_test_pred = tree_fx.predict(X_test) #Prediccion en Test\n",
        "    y_train_pred = tree_fx.predict(X_train) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"DecisionTreeClassifier\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ RandomForestClassifier\n",
        "\n",
        "    #Creamos un random forest!\n",
        "    RandomeForest_fx = RandomForestClassifier(\n",
        "        n_estimators = 50,\n",
        "        random_state = 12,\n",
        "        class_weight = \"balanced\",\n",
        "        criterion = \"entropy\",\n",
        "        max_depth = 30,\n",
        "        min_weight_fraction_leaf = 0.0,\n",
        "        max_features = \"log2\",\n",
        "        max_leaf_nodes = None,\n",
        "        min_impurity_decrease = 0.0,\n",
        "        ccp_alpha = 0.0005\n",
        "        )\n",
        "\n",
        "    RandomeForest_fx.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "    y_test_pred = RandomeForest_fx.predict(X_test) #Prediccion en Test\n",
        "    y_train_pred = RandomeForest_fx.predict(X_train) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"RandomForestClassifier\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ KNeighborsClassifier\n",
        "\n",
        "    knn = KNeighborsClassifier(\n",
        "        n_neighbors=10, # Cuantos puntos a tener en cuenta.\n",
        "        )\n",
        "\n",
        "\n",
        "    knn.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "\n",
        "    y_train_pred = knn.predict(X_train) #Prediccion en Train\n",
        "    y_test_pred = knn.predict(X_test) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"KNeighborsClassifier\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ LogisticRegression\n",
        "\n",
        "\n",
        "    # Paso 4: Creamos una instancia de la Regresión Logística\n",
        "    regresion = LogisticRegression(\n",
        "        random_state=12,\n",
        "        class_weight = \"balanced\",\n",
        "        solver = \"saga\",\n",
        "        max_iter = 100,\n",
        "        multi_class = \"auto\",\n",
        "        warm_start = False,\n",
        "        penalty='l2'\n",
        "    )\n",
        "\n",
        "    # Paso 5: Entrenamos la regresión logística con los datos de entrenamiento\n",
        "    regresion.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "    y_train_pred = regresion.predict(X_train) #Prediccion en Train\n",
        "    y_test_pred = regresion.predict(X_test) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"LogisticRegression\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ SVC\n",
        "    \n",
        "    SVC_model = SVC(\n",
        "        class_weight = \"balanced\",\n",
        "        random_state=12,\n",
        "        C = 150,\n",
        "        kernel = \"poly\", # Poly 27.94\n",
        "        degree = 2 # 1 25.11\n",
        "        )\n",
        "\n",
        "    # Entrenamos el modelo utilizando tree_fx\n",
        "    SVC_model.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "\n",
        "    y_train_pred = SVC_model.predict(X_train) #Prediccion en Train\n",
        "    y_test_pred = SVC_model.predict(X_test) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"SVC\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ GaussianNB\n",
        "\n",
        "    gnb = GaussianNB()\n",
        "\n",
        "    # Entrenamos el modelo utilizando tree_fx\n",
        "    gnb.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "\n",
        "    y_train_pred = gnb.predict(X_train) #Prediccion en Train\n",
        "    y_test_pred = gnb.predict(X_test) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"GaussianNB\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ BernoulliNB\n",
        "\n",
        "    bnb = BernoulliNB()\n",
        "\n",
        "    # Entrenamos el modelo utilizando tree_fx\n",
        "    bnb.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "\n",
        "    y_train_pred = bnb.predict(X_train) #Prediccion en Train\n",
        "    y_test_pred = bnb.predict(X_test) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"BernoulliNB\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ AdaBoostClassifier\n",
        "\n",
        "    adaboost = AdaBoostClassifier(\n",
        "        n_estimators=100, \n",
        "        random_state=0)\n",
        "\n",
        "    # Entrenamos el modelo utilizando tree_fx\n",
        "    adaboost.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "\n",
        "    y_train_pred = adaboost.predict(X_train) #Prediccion en Train\n",
        "    y_test_pred = adaboost.predict(X_test) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"AdaBoostClassifier\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ GradientBoostingClassifier\n",
        "\n",
        "    gbrt = GradientBoostingClassifier(random_state = 12)\n",
        "\n",
        "    # Entrenamos el modelo utilizando tree_fx\n",
        "    gbrt.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "\n",
        "    y_train_pred = gbrt.predict(X_train) #Prediccion en Train\n",
        "    y_test_pred = gbrt.predict(X_test) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"GradientBoostingClassifier\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ lightgbm\n",
        "\n",
        "    clf = lgb.LGBMClassifier(\n",
        "        random_state = 0\n",
        "    )\n",
        "\n",
        "    # Entrenamos el modelo\n",
        "    clf.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "\n",
        "    y_train_pred = clf.predict(X_train) #Prediccion en Train\n",
        "    y_test_pred = clf.predict(X_test) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"lightgbm\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "\n",
        "    ############ xgboost\n",
        "\n",
        "    import xgboost as xgb #pip install xgboost\n",
        "\n",
        "    clf_xgb = xgb.XGBClassifier()\n",
        "\n",
        "    # Entrenamos el modelo\n",
        "    clf_xgb.fit(\n",
        "        X_train,\n",
        "        y_train) #Entrenamos el modelo\n",
        "\n",
        "\n",
        "    y_train_pred = clf_xgb.predict(X_train) #Prediccion en Train\n",
        "    y_test_pred = clf_xgb.predict(X_test) #Prediccion en Test\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    precision_train = precision_score(y_train, y_train_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1score = f1_score(y_test, y_test_pred)\n",
        "    roc = roc_auc_score(y_test, y_test_pred)\n",
        "    matriz = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    count = pd.DataFrame(y_test_pred).value_counts()\n",
        "    if count.index.size > 1:\n",
        "      count =  count.loc[1].values[0]\n",
        "    else:\n",
        "      count = 0\n",
        "\n",
        "    result.loc[c] =  [ list_test , \"xgboost\", accuracy, precision, precision_train, recall, f1score, roc, count , matriz ]\n",
        "    c += 1\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4lE_K61y0YL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dbfc0b6-ebc8-48c1-f563-d841a538746c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5516: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[name] = value\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1C3-bmk9pSUJRMaBTb7F1OUCAJu_4HC1xe6EgWE4xdVU',\n",
              " 'updatedCells': 53603,\n",
              " 'updatedColumns': 11,\n",
              " 'updatedRange': 'Initial_results!A1:K4873',\n",
              " 'updatedRows': 4873}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Include difference column into DataSet\n",
        "result[\"precision_difference\"] =  ( result.precision - result.precision_train )/ result.precision_train\n",
        "result = result.dropna()\n",
        "result.precision_difference = result.precision_difference.replace([np.inf, -np.inf],0)\n",
        "result.matrix = result.matrix.astype(str)           \n",
        "\n",
        "# Save data into t-sheet\n",
        "t_sheet_url = \"https://docs.google.com/spreadsheets/XXXXX" # Replace with your own file URL\n",
        "tab_name = \"Initial_results\"\n",
        "\n",
        "worksheet_result = gc.open_by_url(t_sheet_url)\n",
        "\n",
        "worksheet_result.worksheet(tab_name).update( \n",
        "    \"A1\",\n",
        "    [result.columns.values.tolist()] + result.values.tolist()\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiVbpXucz749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "263f3ee4-439b-4fbd-b506-1f0c589da37a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Dataframe                      Modelo  accuracy  \\\n",
              "0                     Baja///      DecisionTreeClassifier  0.603951   \n",
              "1                     Baja///      RandomForestClassifier  0.575729   \n",
              "2                     Baja///        KNeighborsClassifier  0.601129   \n",
              "3                     Baja///          LogisticRegression  0.502352   \n",
              "4                     Baja///                         SVC  0.463782   \n",
              "...                       ...                         ...       ...   \n",
              "5275  /Undersample/Normal/PCA                 BernoulliNB  0.511920   \n",
              "5276  /Undersample/Normal/PCA          AdaBoostClassifier  0.547051   \n",
              "5277  /Undersample/Normal/PCA  GradientBoostingClassifier  0.524467   \n",
              "5278  /Undersample/Normal/PCA                    lightgbm  0.508783   \n",
              "5279  /Undersample/Normal/PCA                     xgboost  0.536386   \n",
              "\n",
              "      precision  precision_train    recall   f1score       roc count  \\\n",
              "0      0.365854         0.406186  0.115979  0.176125  0.500212   123   \n",
              "1      0.375494         0.994156  0.244845  0.296412  0.505386   253   \n",
              "2      0.352459         0.646154  0.110825  0.168627  0.496894   122   \n",
              "3      0.365714         0.381491  0.494845  0.420591  0.500756   525   \n",
              "4      0.372905         0.383197  0.688144  0.483696  0.511480   716   \n",
              "...         ...              ...       ...       ...       ...   ...   \n",
              "5275   0.381643         0.512605  0.542955  0.448227  0.518513   828   \n",
              "5276   0.377622         0.593654  0.371134  0.374350  0.509678   572   \n",
              "5277   0.364615         0.655020  0.407216  0.384740  0.499557   650   \n",
              "5278   0.351551         0.640114  0.408935  0.378078  0.487570   677   \n",
              "5279   0.365352         0.643802  0.365979  0.365665  0.500183   583   \n",
              "\n",
              "                       matrix  precision_difference  \n",
              "0     [[597  78]\\n [343  45]]             -0.099294  \n",
              "1     [[517 158]\\n [293  95]]             -0.622299  \n",
              "2     [[596  79]\\n [345  43]]             -0.454528  \n",
              "3     [[342 333]\\n [196 192]]             -0.041355  \n",
              "4     [[226 449]\\n [121 267]]             -0.026859  \n",
              "...                       ...                   ...  \n",
              "5275  [[500 512]\\n [266 316]]             -0.255484  \n",
              "5276  [[656 356]\\n [366 216]]             -0.363902  \n",
              "5277  [[599 413]\\n [345 237]]             -0.443352  \n",
              "5278  [[573 439]\\n [344 238]]             -0.450800  \n",
              "5279  [[642 370]\\n [369 213]]             -0.432509  \n",
              "\n",
              "[4872 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6ceb9c7-c19a-4dd6-aec8-ab75549ca5b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataframe</th>\n",
              "      <th>Modelo</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>precision_train</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1score</th>\n",
              "      <th>roc</th>\n",
              "      <th>count</th>\n",
              "      <th>matrix</th>\n",
              "      <th>precision_difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baja///</td>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.603951</td>\n",
              "      <td>0.365854</td>\n",
              "      <td>0.406186</td>\n",
              "      <td>0.115979</td>\n",
              "      <td>0.176125</td>\n",
              "      <td>0.500212</td>\n",
              "      <td>123</td>\n",
              "      <td>[[597  78]\\n [343  45]]</td>\n",
              "      <td>-0.099294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Baja///</td>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.575729</td>\n",
              "      <td>0.375494</td>\n",
              "      <td>0.994156</td>\n",
              "      <td>0.244845</td>\n",
              "      <td>0.296412</td>\n",
              "      <td>0.505386</td>\n",
              "      <td>253</td>\n",
              "      <td>[[517 158]\\n [293  95]]</td>\n",
              "      <td>-0.622299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Baja///</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.601129</td>\n",
              "      <td>0.352459</td>\n",
              "      <td>0.646154</td>\n",
              "      <td>0.110825</td>\n",
              "      <td>0.168627</td>\n",
              "      <td>0.496894</td>\n",
              "      <td>122</td>\n",
              "      <td>[[596  79]\\n [345  43]]</td>\n",
              "      <td>-0.454528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Baja///</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.502352</td>\n",
              "      <td>0.365714</td>\n",
              "      <td>0.381491</td>\n",
              "      <td>0.494845</td>\n",
              "      <td>0.420591</td>\n",
              "      <td>0.500756</td>\n",
              "      <td>525</td>\n",
              "      <td>[[342 333]\\n [196 192]]</td>\n",
              "      <td>-0.041355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Baja///</td>\n",
              "      <td>SVC</td>\n",
              "      <td>0.463782</td>\n",
              "      <td>0.372905</td>\n",
              "      <td>0.383197</td>\n",
              "      <td>0.688144</td>\n",
              "      <td>0.483696</td>\n",
              "      <td>0.511480</td>\n",
              "      <td>716</td>\n",
              "      <td>[[226 449]\\n [121 267]]</td>\n",
              "      <td>-0.026859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5275</th>\n",
              "      <td>/Undersample/Normal/PCA</td>\n",
              "      <td>BernoulliNB</td>\n",
              "      <td>0.511920</td>\n",
              "      <td>0.381643</td>\n",
              "      <td>0.512605</td>\n",
              "      <td>0.542955</td>\n",
              "      <td>0.448227</td>\n",
              "      <td>0.518513</td>\n",
              "      <td>828</td>\n",
              "      <td>[[500 512]\\n [266 316]]</td>\n",
              "      <td>-0.255484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5276</th>\n",
              "      <td>/Undersample/Normal/PCA</td>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>0.547051</td>\n",
              "      <td>0.377622</td>\n",
              "      <td>0.593654</td>\n",
              "      <td>0.371134</td>\n",
              "      <td>0.374350</td>\n",
              "      <td>0.509678</td>\n",
              "      <td>572</td>\n",
              "      <td>[[656 356]\\n [366 216]]</td>\n",
              "      <td>-0.363902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5277</th>\n",
              "      <td>/Undersample/Normal/PCA</td>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.524467</td>\n",
              "      <td>0.364615</td>\n",
              "      <td>0.655020</td>\n",
              "      <td>0.407216</td>\n",
              "      <td>0.384740</td>\n",
              "      <td>0.499557</td>\n",
              "      <td>650</td>\n",
              "      <td>[[599 413]\\n [345 237]]</td>\n",
              "      <td>-0.443352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5278</th>\n",
              "      <td>/Undersample/Normal/PCA</td>\n",
              "      <td>lightgbm</td>\n",
              "      <td>0.508783</td>\n",
              "      <td>0.351551</td>\n",
              "      <td>0.640114</td>\n",
              "      <td>0.408935</td>\n",
              "      <td>0.378078</td>\n",
              "      <td>0.487570</td>\n",
              "      <td>677</td>\n",
              "      <td>[[573 439]\\n [344 238]]</td>\n",
              "      <td>-0.450800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5279</th>\n",
              "      <td>/Undersample/Normal/PCA</td>\n",
              "      <td>xgboost</td>\n",
              "      <td>0.536386</td>\n",
              "      <td>0.365352</td>\n",
              "      <td>0.643802</td>\n",
              "      <td>0.365979</td>\n",
              "      <td>0.365665</td>\n",
              "      <td>0.500183</td>\n",
              "      <td>583</td>\n",
              "      <td>[[642 370]\\n [369 213]]</td>\n",
              "      <td>-0.432509</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4872 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6ceb9c7-c19a-4dd6-aec8-ab75549ca5b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6ceb9c7-c19a-4dd6-aec8-ab75549ca5b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6ceb9c7-c19a-4dd6-aec8-ab75549ca5b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmwenGz1UXIn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "dd53b5df-69d7-4470-a352-c4676023f205"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     bull  D_MVA200    length    heigth  gain  \\\n",
              "date                                                            \n",
              "2001-12-18 22:00:00     0  0.015347  0.007654  0.007930     1   \n",
              "2002-01-03 14:00:00     0  0.009830  0.005103  0.014986     1   \n",
              "2002-02-20 10:00:00     0 -0.006545  0.006379  0.019418     0   \n",
              "2002-02-22 18:00:00     0  0.000544  0.020412  0.009097     1   \n",
              "2002-08-26 17:00:00     0 -0.018400  0.006379  0.005752     0   \n",
              "...                   ...       ...       ...       ...   ...   \n",
              "2019-08-05 05:00:00     0 -0.019948  0.007654  0.012953     0   \n",
              "2019-08-06 01:00:00     0 -0.015159  0.017860  0.022687     1   \n",
              "2019-09-16 13:00:00     0 -0.014224  0.007654  0.021074     0   \n",
              "2019-10-22 05:00:00     0  0.003513  0.008930  0.010014     1   \n",
              "2019-10-23 17:00:00     0  0.003874  0.006379  0.005268     1   \n",
              "\n",
              "                     MVA200_interact  D_target  D_stop_trade  \\\n",
              "date                                                           \n",
              "2001-12-18 22:00:00                0  2.862233      1.931116   \n",
              "2002-01-03 14:00:00                0  4.519126      2.759563   \n",
              "2002-02-20 10:00:00                1  5.560000      3.280000   \n",
              "2002-02-22 18:00:00                0  3.136240      2.068120   \n",
              "2002-08-26 17:00:00                0  2.350877      1.675439   \n",
              "...                              ...       ...           ...   \n",
              "2019-08-05 05:00:00                0  4.041715      2.520857   \n",
              "2019-08-06 01:00:00                0  6.327645      3.663823   \n",
              "2019-09-16 13:00:00                0  5.948837      3.474419   \n",
              "2019-10-22 05:00:00                0  3.351731      2.175866   \n",
              "2019-10-23 17:00:00                0  2.237209      1.618605   \n",
              "\n",
              "                     type_Double Bottom  type_Double Top  \\\n",
              "date                                                       \n",
              "2001-12-18 22:00:00                   0                1   \n",
              "2002-01-03 14:00:00                   0                1   \n",
              "2002-02-20 10:00:00                   0                1   \n",
              "2002-02-22 18:00:00                   0                1   \n",
              "2002-08-26 17:00:00                   0                1   \n",
              "...                                 ...              ...   \n",
              "2019-08-05 05:00:00                   0                1   \n",
              "2019-08-06 01:00:00                   0                1   \n",
              "2019-09-16 13:00:00                   0                1   \n",
              "2019-10-22 05:00:00                   0                1   \n",
              "2019-10-23 17:00:00                   0                1   \n",
              "\n",
              "                     resistance_support_none  resistance_support_below  \\\n",
              "date                                                                     \n",
              "2001-12-18 22:00:00                        0                         1   \n",
              "2002-01-03 14:00:00                        0                         1   \n",
              "2002-02-20 10:00:00                        0                         1   \n",
              "2002-02-22 18:00:00                        0                         1   \n",
              "2002-08-26 17:00:00                        0                         1   \n",
              "...                                      ...                       ...   \n",
              "2019-08-05 05:00:00                        0                         1   \n",
              "2019-08-06 01:00:00                        0                         1   \n",
              "2019-09-16 13:00:00                        0                         1   \n",
              "2019-10-22 05:00:00                        0                         1   \n",
              "2019-10-23 17:00:00                        0                         1   \n",
              "\n",
              "                     resistance_support_over  resistance_support_inside  \n",
              "date                                                                     \n",
              "2001-12-18 22:00:00                        0                          0  \n",
              "2002-01-03 14:00:00                        0                          0  \n",
              "2002-02-20 10:00:00                        0                          0  \n",
              "2002-02-22 18:00:00                        0                          0  \n",
              "2002-08-26 17:00:00                        0                          0  \n",
              "...                                      ...                        ...  \n",
              "2019-08-05 05:00:00                        0                          0  \n",
              "2019-08-06 01:00:00                        0                          0  \n",
              "2019-09-16 13:00:00                        0                          0  \n",
              "2019-10-22 05:00:00                        0                          0  \n",
              "2019-10-23 17:00:00                        0                          0  \n",
              "\n",
              "[5312 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-252908bd-2576-4a52-b8f5-2d8cc65cb44c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bull</th>\n",
              "      <th>D_MVA200</th>\n",
              "      <th>length</th>\n",
              "      <th>heigth</th>\n",
              "      <th>gain</th>\n",
              "      <th>MVA200_interact</th>\n",
              "      <th>D_target</th>\n",
              "      <th>D_stop_trade</th>\n",
              "      <th>type_Double Bottom</th>\n",
              "      <th>type_Double Top</th>\n",
              "      <th>resistance_support_none</th>\n",
              "      <th>resistance_support_below</th>\n",
              "      <th>resistance_support_over</th>\n",
              "      <th>resistance_support_inside</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2001-12-18 22:00:00</th>\n",
              "      <td>0</td>\n",
              "      <td>0.015347</td>\n",
              "      <td>0.007654</td>\n",
              "      <td>0.007930</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.862233</td>\n",
              "      <td>1.931116</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-03 14:00:00</th>\n",
              "      <td>0</td>\n",
              "      <td>0.009830</td>\n",
              "      <td>0.005103</td>\n",
              "      <td>0.014986</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.519126</td>\n",
              "      <td>2.759563</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-02-20 10:00:00</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.006545</td>\n",
              "      <td>0.006379</td>\n",
              "      <td>0.019418</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5.560000</td>\n",
              "      <td>3.280000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-02-22 18:00:00</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000544</td>\n",
              "      <td>0.020412</td>\n",
              "      <td>0.009097</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3.136240</td>\n",
              "      <td>2.068120</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-08-26 17:00:00</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.018400</td>\n",
              "      <td>0.006379</td>\n",
              "      <td>0.005752</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.350877</td>\n",
              "      <td>1.675439</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-05 05:00:00</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.019948</td>\n",
              "      <td>0.007654</td>\n",
              "      <td>0.012953</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.041715</td>\n",
              "      <td>2.520857</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-06 01:00:00</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.015159</td>\n",
              "      <td>0.017860</td>\n",
              "      <td>0.022687</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6.327645</td>\n",
              "      <td>3.663823</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-09-16 13:00:00</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.014224</td>\n",
              "      <td>0.007654</td>\n",
              "      <td>0.021074</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.948837</td>\n",
              "      <td>3.474419</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-22 05:00:00</th>\n",
              "      <td>0</td>\n",
              "      <td>0.003513</td>\n",
              "      <td>0.008930</td>\n",
              "      <td>0.010014</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3.351731</td>\n",
              "      <td>2.175866</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-23 17:00:00</th>\n",
              "      <td>0</td>\n",
              "      <td>0.003874</td>\n",
              "      <td>0.006379</td>\n",
              "      <td>0.005268</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.237209</td>\n",
              "      <td>1.618605</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5312 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-252908bd-2576-4a52-b8f5-2d8cc65cb44c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-252908bd-2576-4a52-b8f5-2d8cc65cb44c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-252908bd-2576-4a52-b8f5-2d8cc65cb44c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MSseiEDMBEVq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "First Model testing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
